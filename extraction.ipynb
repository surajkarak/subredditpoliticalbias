{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WlwHY9JHwVz4"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import sqlite3\n",
        "import os\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-hY2GVMjwVz6"
      },
      "outputs": [],
      "source": [
        "# note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'\n",
        "auth = requests.auth.HTTPBasicAuth('liSqdZAKoID2d-bIQH5M9A', 'tecIJkvcWwnQK9exC0fHNCnudtdYVA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "53xJD9zfwVz7"
      },
      "outputs": [],
      "source": [
        "# here we pass our login method (password), username, and password\n",
        "data = {'grant_type': 'password'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zTpkQRa-wVz7"
      },
      "outputs": [],
      "source": [
        "with open('pw.txt', 'r') as file:\n",
        "# Step 2: Read the contents of the file\n",
        "        lines = file.readlines()\n",
        "\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "                # Split the line into username and password\n",
        "                username, password = line.strip().split(':')\n",
        "\n",
        "                # Store the username and password in the dictionary\n",
        "                data['username'] = username\n",
        "                data['password'] = password"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Moptm3-SwVz7"
      },
      "outputs": [],
      "source": [
        "# setup our header info, which gives reddit a brief description of our app\n",
        "headers = {'User-Agent': 'MySideProject/0.0.1'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "UOcXBTS3wVz8"
      },
      "outputs": [],
      "source": [
        "# send our request for an OAuth token\n",
        "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
        "                    auth=auth, data=data, headers=headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VWTv2UCpwVz8"
      },
      "outputs": [],
      "source": [
        "# convert response to JSON and pull access_token value\n",
        "TOKEN = res.json()['access_token']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "HDDJYcF2wVz8"
      },
      "outputs": [],
      "source": [
        "# add authorization to our headers dictionary\n",
        "headers['Authorization']=f'bearer {TOKEN}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OfJIHJwCwVz8"
      },
      "outputs": [],
      "source": [
        "def df_from_response(res):\n",
        "    # initialize temp list to store dictionaries\n",
        "    data_list = []\n",
        "\n",
        "    # loop through each post pulled from res and append to data_list\n",
        "    for post in res.json()['data']['children']:\n",
        "        data_list.append({\n",
        "            'subreddit': post['data']['subreddit'],\n",
        "            'title': post['data']['title'],\n",
        "            'selftext': post['data']['selftext'],\n",
        "            'upvote_ratio': post['data']['upvote_ratio'],\n",
        "            'ups': post['data']['ups'],\n",
        "            'downs': post['data']['downs'],\n",
        "            'score': post['data']['score'],\n",
        "            'link_flair_css_class': post['data']['link_flair_css_class'],\n",
        "            'created_utc': datetime.fromtimestamp(post['data']['created_utc']).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
        "            'id': post['data']['id'],\n",
        "            'kind': post['kind']\n",
        "        })\n",
        "\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yPkAl_Z-ScL"
      },
      "source": [
        "Subreddits to explore\n",
        "\n",
        "- politics\n",
        "- worldnews\n",
        "- news\n",
        "- energy\n",
        "- environment\n",
        "- business\n",
        "- worldevents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-Na4GcnGwVz8"
      },
      "outputs": [],
      "source": [
        "def extract_and_add_to_database(subreddit_name, conn):\n",
        "    # Initialize dataframe and parameters for pulling data in loop\n",
        "    data = pd.DataFrame()\n",
        "    params = {'limit': 100}\n",
        "\n",
        "    # Loop through 10 times (returning 1K posts)\n",
        "    for i in range(10):\n",
        "        # Make request to the specified subreddit\n",
        "        res = requests.get(f\"https://oauth.reddit.com/r/{subreddit_name}/new\",\n",
        "                           headers=headers,\n",
        "                           params=params)\n",
        "\n",
        "        # Get list of dictionaries from response\n",
        "        data_list = df_from_response(res)\n",
        "\n",
        "        # Convert list of dictionaries to DataFrame and append to data\n",
        "        data = pd.concat([data, pd.DataFrame(data_list)], ignore_index=True)\n",
        "\n",
        "        # Take the final row (oldest entry)\n",
        "        row = data_list[-1]\n",
        "        # Create fullname\n",
        "        fullname = row['kind'] + '_' + row['id']\n",
        "        # Add/update fullname in params\n",
        "        params['after'] = fullname\n",
        "\n",
        "    # Create a cursor object to execute SQL commands\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Insert data into the table\n",
        "    for index, row in data.iterrows():\n",
        "        cursor.execute('''INSERT INTO reddit_posts\n",
        "                          (subreddit, title, selftext, upvote_ratio, ups, downs, score,\n",
        "                           link_flair_css_class, created_utc, kind)\n",
        "                          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
        "                       (row['subreddit'], row['title'], row['selftext'], row['upvote_ratio'],\n",
        "                        row['ups'], row['downs'], row['score'], row['link_flair_css_class'],\n",
        "                        row['created_utc'], row['kind']))\n",
        "\n",
        "    # Commit changes\n",
        "    conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "_crAGMVLwVz9"
      },
      "outputs": [],
      "source": [
        "# Connect to SQLite database (create if it doesn't exist)\n",
        "conn = sqlite3.connect('reddit_data.db')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qWQ40y4GwVz9"
      },
      "outputs": [],
      "source": [
        "# Create a cursor object to execute SQL commands\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaLVaRZNwVz9",
        "outputId": "d3f6b282-5bd1-459c-bd3c-4fd520e253ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x17a43e640>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a table to store your data\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS reddit_posts (\n",
        "                    id INTEGER PRIMARY KEY,\n",
        "                    subreddit TEXT,\n",
        "                    title TEXT,\n",
        "                    selftext TEXT,\n",
        "                    upvote_ratio REAL,\n",
        "                    ups INTEGER,\n",
        "                    downs INTEGER,\n",
        "                    score INTEGER,\n",
        "                    link_flair_css_class TEXT,\n",
        "                    created_utc INTEGER,\n",
        "                    kind TEXT,\n",
        "                    cleaned TEXT\n",
        "                )''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_and_add_to_database(subreddit_name, conn):\n",
        "    # Initialize dataframe and parameters for pulling data in loop\n",
        "    data = pd.DataFrame()\n",
        "    params = {'limit': 100}\n",
        "\n",
        "    # Loop through 10 times (returning 1K posts)\n",
        "    for i in range(10):\n",
        "        # Make request to the specified subreddit\n",
        "        res = requests.get(f\"https://oauth.reddit.com/r/{subreddit_name}/new\",\n",
        "                           headers=headers,\n",
        "                           params=params)\n",
        "\n",
        "        # Get list of dictionaries from response\n",
        "        data_list = df_from_response(res)\n",
        "\n",
        "        # Convert list of dictionaries to DataFrame and append to data\n",
        "        data = pd.concat([data, pd.DataFrame(data_list)], ignore_index=True)\n",
        "\n",
        "        # Take the final row (oldest entry)\n",
        "        row = data_list[-1]\n",
        "        # Create fullname\n",
        "        fullname = row['kind'] + '_' + row['id']\n",
        "        # Add/update fullname in params\n",
        "        params['after'] = fullname\n",
        "\n",
        "    # Create a cursor object to execute SQL commands\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Insert data into the table\n",
        "    for index, row in data.iterrows():\n",
        "        cursor.execute('''INSERT INTO reddit_posts\n",
        "                          (subreddit, title, selftext, upvote_ratio, ups, downs, score,\n",
        "                           link_flair_css_class, created_utc, kind)\n",
        "                          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
        "                       (row['subreddit'], row['title'], row['selftext'], row['upvote_ratio'],\n",
        "                        row['ups'], row['downs'], row['score'], row['link_flair_css_class'],\n",
        "                        row['created_utc'], row['kind']))\n",
        "\n",
        "    # Commit changes\n",
        "    conn.commit()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('reddit_data.db')\n",
        "\n",
        "# Extract data from a specific subreddit and add it to the database\n",
        "extract_and_add_to_database('worldnews', conn)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- politics\n",
        "- worldnews\n",
        "- news\n",
        "- energy\n",
        "- environment\n",
        "- business\n",
        "- worldevents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_and_add_to_database('politics', conn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_and_add_to_database('worldevents', conn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_and_add_to_database('ukpolitics', conn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_and_add_to_database('AskReddit', conn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close connection\n",
        "conn.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
